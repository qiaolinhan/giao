[net]
# testing
# batch = 1
# subdivisions = 1
# Training
batch = 4
subdivisions = 1
width = 416
height = 416
channels = 3
momentum = 0.9
decay = 0.0005
angle = 0
saturation = 1.5
exposure = 1.5
hue = .1

learning_rate = 0.0001
burn_in = 1000
max_batches = 500200
policy = steps
steps = 400000, 450000
scales = .1, .1

[convolutional]
batch_normalize = 1
filter = 32
size = 3
stride = 1
pad = 1
activation = leaky

# Downsample

[convolutional]
batch_normalize = 1
filter = 64
size = 3
stride = 2
pad = 1
activation = leaky

[convolutional]
batch_normalize = 1
filters = 32
size = 3
stride = 1
pad = 1
activation = leaky

[shortcut]
from = -3
activation = linear

# Downsample

[convolutional]
batch_normalize = 1
filters = 128
size = 3
stride = 2
pad = 1
activation = leaky

[convolutional]
batch_normalize = 1
filters = 64
size = 1
stride = 1

